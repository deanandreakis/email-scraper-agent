[project]
name = "email-scraper-agent"
version = "1.0.0"
description = "AI agent that uses Google Gemini AI and custom web scraper to extract emails from websites based on topics"
authors = [
    { name = "Email Scraper Agent Team" }
]
readme = "README.md"
license = { text = "MIT" }
requires-python = ">=3.9"
keywords = ["ai", "agent", "web-scraping", "email", "gemini", "google-ai", "httpx"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Software Development :: Libraries :: Python Modules",
    "Topic :: Internet :: WWW/HTTP :: Indexing/Search",
]

dependencies = [
    # Google Agent Development Kit
    "google-generativeai>=0.3.0",
    "google-cloud-aiplatform>=1.38.0",

    # Legacy Web Scraping (deprecated, kept for compatibility)
    "crawlee>=0.0.7",

    # Web Scraping & HTTP (current implementation)
    "httpx>=0.25.0",
    "beautifulsoup4>=4.12.0",
    "lxml>=4.9.0",
    "requests>=2.31.0",

    # Email Validation
    "email-validator>=2.1.0",
    "dnspython>=2.4.0",

    # Data Processing
    "pandas>=2.0.0",
    "python-dateutil>=2.8.0",

    # Configuration & Environment
    "python-dotenv>=1.0.0",
    "pydantic>=2.0.0",
    "pydantic-settings>=2.0.0",

    # Utilities
    "aiohttp>=3.9.0",
    "tldextract>=5.0.0",

    # CLI
    "click>=8.1.0",
    "rich>=13.0.0",

    # Logging
    "loguru>=0.7.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.0.0",
    "pytest-asyncio>=0.21.0",
    "pytest-cov>=4.0.0",
    "black>=23.0.0",
    "ruff>=0.1.0",
    "mypy>=1.0.0",
]

[project.scripts]
email-scraper = "main:cli"

[project.urls]
Homepage = "https://github.com/deanandreakis/email-scraper-agent"
Repository = "https://github.com/deanandreakis/email-scraper-agent"
Issues = "https://github.com/deanandreakis/email-scraper-agent/issues"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["."]

[tool.ruff]
line-length = 100
target-version = "py39"

[tool.ruff.lint]
select = [
    "E",   # pycodestyle errors
    "W",   # pycodestyle warnings
    "F",   # pyflakes
    "I",   # isort
    "B",   # flake8-bugbear
    "C4",  # flake8-comprehensions
    "UP",  # pyupgrade
]
ignore = [
    "E501",  # line too long (handled by formatter)
    "B008",  # do not perform function calls in argument defaults
]

[tool.ruff.lint.isort]
known-first-party = ["email_scraper_agent"]

[tool.black]
line-length = 100
target-version = ["py39", "py310", "py311", "py312"]

[tool.mypy]
python_version = "3.9"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = false
ignore_missing_imports = true

[tool.pytest.ini_options]
asyncio_mode = "auto"
testpaths = ["tests"]
python_files = "test_*.py"
python_classes = "Test*"
python_functions = "test_*"
addopts = "-v --cov=. --cov-report=term-missing"

[tool.coverage.run]
omit = [
    "tests/*",
    "venv/*",
    ".venv/*",
]

[tool.coverage.report]
exclude_lines = [
    "pragma: no cover",
    "def __repr__",
    "raise AssertionError",
    "raise NotImplementedError",
    "if __name__ == .__main__.:",
    "if TYPE_CHECKING:",
]
